{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "img=mpimg.imread('D:/FaraDars.org/T1059/MACHINELEARN/6/code_6/Neurons.png')\n",
    "a = plt.imshow(img)\n",
    "a;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nHOURS STUDIED     HOURS SLEPT        \\t        TEST SCORE \\n    2                  9\\t                         92\\n    1                  5\\t                         86\\n    3                  6\\t                         89\\n    5                  10\\t                         ?\\n\\n\\n (2 * .2) + (9 * .8) = 7.6      S(7.6) = 0.999499799\\n (2 * .6) + (9 * .3) = 3.9      S(7.5) = 1.000553084\\n (2 * .1) + (9 * .7) = 6.5      S(6.5) = 0.998498818\\n\\n\\n(.9994 * .4) + (1.000 * .5) + (.9984 * .9) = 1.79832     S(1.79832) = .8579443067\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "HOURS STUDIED     HOURS SLEPT        \t        TEST SCORE \n",
    "    2                  9\t                         92\n",
    "    1                  5\t                         86\n",
    "    3                  6\t                         89\n",
    "    5                  10\t                         ?\n",
    "\n",
    "\n",
    " (2 * .2) + (9 * .8) = 7.6      S(7.6) = 0.999499799\n",
    " (2 * .6) + (9 * .3) = 3.9      S(7.5) = 1.000553084\n",
    " (2 * .1) + (9 * .7) = 6.5      S(6.5) = 0.998498818\n",
    "\n",
    "\n",
    "(.9994 * .4) + (1.000 * .5) + (.9984 * .9) = 1.79832     S(1.79832) = .8579443067\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  9.],\n",
       "       [ 1.,  5.],\n",
       "       [ 3.,  6.],\n",
       "       [ 5., 10.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xAll = np.array(([2, 9], [1, 5], [3, 6], [5, 10]), dtype=float)   #(hours studying, hours sleeping)\n",
    "xAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4, 0.9],\n",
       "       [0.2, 0.5],\n",
       "       [0.6, 0.6],\n",
       "       [1. , 1. ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scaling input data\n",
    "xAll = xAll/np.amax(xAll, axis=0)   \n",
    "xAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[92.],\n",
       "       [86.],\n",
       "       [89.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(([92], [86], [89]), dtype=float)   # y = score on test\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.92],\n",
       "       [0.86],\n",
       "       [0.89]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scaling output data (max test score is 100)\n",
    "y = y/100      \n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4, 0.9],\n",
       "       [0.2, 0.5],\n",
       "       [0.6, 0.6]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training data\n",
    "X = np.split(xAll, [3])[0]           \n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest = np.split(xAll, [3])[1]   # testing data\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network(object):\n",
    "    def __init__(self):\n",
    "        self.inputSize  = 2\n",
    "        self.outputSize = 1\n",
    "        self.hiddenSize = 3\n",
    "        self.W1 = np.random.randn(self.inputSize, self.hiddenSize)    # (3x2) weight matrix from input to hidden layer\n",
    "        self.W2 = np.random.randn(self.hiddenSize, self.outputSize)   #(3x1) weight matrix from hidden to output layer\n",
    "\n",
    "    #forward propagation \n",
    "    def forward(self, X):\n",
    "      self.z  = np.dot(X, self.W1)          # dot product of X (input) and first set of 3x2 weights\n",
    "      self.z2 = self.sigmoid(self.z)        # activation function\n",
    "      self.z3 = np.dot(self.z2, self.W2)    # dot product of hidden layer (z2) and second set of 3x1 weights\n",
    "      o = self.sigmoid(self.z3)             # final activation function\n",
    "      return o\n",
    "\n",
    "    # activation function\n",
    "    def sigmoid(self, s):\n",
    "      return 1/(1+np.exp(-s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = Neural_Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52933586],\n",
       "       [0.52858312],\n",
       "       [0.52640196]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = NN.forward(X)    \n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.92],\n",
       "       [0.86],\n",
       "       [0.89]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward Propagate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoidPrime(self, s):\n",
    "    return s * (1 - s)\n",
    "\n",
    "def backward(self, X, y, o):\n",
    "    self.o_error = y - o                                     # error in output\n",
    "    self.o_delta = self.o_error*self.sigmoidPrime(o)         # applying derivative of sigmoid to error\n",
    "\n",
    "    self.z2_error = self.o_delta.dot(self.W2.T)   # z2 error: how much our hidden layer weights contributed to output error\n",
    "    self.z2_delta = self.z2_error*self.sigmoidPrime(self.z2) # applying derivative of sigmoid to z2 error\n",
    "\n",
    "    self.W1 += X.T.dot(self.z2_delta)                        # adjusting first set (input --> hidden) weights\n",
    "    self.W2 += self.z2.T.dot(self.o_delta)                   # adjusting second set (hidden --> output) weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self, X, y):\n",
    "    o = self.forward(X)\n",
    "    self.backward(X, y, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveWeights(self):\n",
    "    np.savetxt(\"w1.txt\", self.W1, fmt=\"%s\")\n",
    "    np.savetxt(\"w2.txt\", self.W2, fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self):\n",
    "    print( \"Predicted data based on trained weights: \");\n",
    "    print( \"Input (scaled): \\n\" + str(xPredicted));\n",
    "    print( \"Output: \\n\" + str(self.forward(xPredicted)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = Neural_Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def think(self, inputs):\n",
    "    #pass inputs through our single neuron(our single neuron)\n",
    "    return self.___sigmoid(dot(inputs, self.synaptic_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:0\n",
      "Loss: 0.015811222854921658\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Neural_Network' object has no attribute 'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-b22e94d07578>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Loss: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m   \u001b[0mNN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Neural_Network' object has no attribute 'train'"
     ]
    }
   ],
   "source": [
    "for i in range(3):                          \n",
    "  print (\"iteration:\" + str(i) )\n",
    "  k=np.mean(np.square(y - NN.forward(X)))    # mean sum squared loss\n",
    "  print (\"Loss: \" + str(k))       \n",
    "  print (\"\\n\")\n",
    "  NN.train(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
